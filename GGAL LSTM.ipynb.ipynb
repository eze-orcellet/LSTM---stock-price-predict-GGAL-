{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YcOzch4-KQbH"
      },
      "outputs": [],
      "source": [
        "!pip install yfinance\n",
        "!pip install ta"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "from ta import add_all_ta_features\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n"
      ],
      "metadata": {
        "id": "b-l22DaWKS1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df = pd.read_csv('GGAL (1).csv')\n",
        "ggal = yf.Ticker(\"ggal\")\n",
        "df = ggal.history(interval='1d', start='2001-01-01', end='2024-02-23')\n",
        "# df.to_csv('ggal.csv')\n",
        "# df = pd.read_csv('ggal.csv')"
      ],
      "metadata": {
        "id": "WCkvJaiqKSyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular todas las características técnicas\n",
        "df = add_all_ta_features(df, open=\"Open\", high=\"High\", low=\"Low\", close=\"Close\", volume=\"Volume\", fillna=True)\n",
        "\n",
        "df[\"Tomorrow\"] = df[\"Close\"].shift(-1)\n",
        "\n",
        "df[\"Target\"] = (df[\"Tomorrow\"] > df[\"Close\"]).astype(int)\n",
        "\n",
        "df = df.drop(['Dividends', 'Stock Splits'], axis = 1 )\n",
        "\n",
        "df.index = df.index.tz_localize(None)\n",
        "\n",
        "df = df.dropna()"
      ],
      "metadata": {
        "id": "OPXOAl-KKSvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test = train_test_split(df, test_size=0.2, shuffle=False)"
      ],
      "metadata": {
        "id": "iCJwTRfhKSnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictors = ['Open',\n",
        " 'High',\n",
        " 'Low',\n",
        " 'Close',\n",
        " 'Volume',\n",
        " 'volume_adi',\n",
        " 'volume_obv',\n",
        " 'volume_cmf',\n",
        " 'volume_fi',\n",
        " 'volume_em',\n",
        " 'volume_sma_em',\n",
        " 'volume_vpt',\n",
        " 'volume_vwap',\n",
        " 'volume_mfi',\n",
        " 'volume_nvi',\n",
        " 'volatility_bbm',\n",
        " 'volatility_bbh',\n",
        " 'volatility_bbl',\n",
        " 'volatility_bbw',\n",
        " 'volatility_bbp',\n",
        " 'volatility_bbhi',\n",
        " 'volatility_bbli',\n",
        " 'volatility_kcc',\n",
        " 'volatility_kch',\n",
        " 'volatility_kcl',\n",
        " 'volatility_kcw',\n",
        " 'volatility_kcp',\n",
        " 'volatility_kchi',\n",
        " 'volatility_kcli',\n",
        " 'volatility_dcl',\n",
        " 'volatility_dch',\n",
        " 'volatility_dcm',\n",
        " 'volatility_dcw',\n",
        " 'volatility_dcp',\n",
        " 'volatility_atr',\n",
        " 'volatility_ui',\n",
        " 'trend_macd',\n",
        " 'trend_macd_signal',\n",
        " 'trend_macd_diff',\n",
        " 'trend_sma_fast',\n",
        " 'trend_sma_slow',\n",
        " 'trend_ema_fast',\n",
        " 'trend_ema_slow',\n",
        " 'trend_vortex_ind_pos',\n",
        " 'trend_vortex_ind_neg',\n",
        " 'trend_vortex_ind_diff',\n",
        " 'trend_trix',\n",
        " 'trend_mass_index',\n",
        " 'trend_dpo',\n",
        " 'trend_kst',\n",
        " 'trend_kst_sig',\n",
        " 'trend_kst_diff',\n",
        " 'trend_ichimoku_conv',\n",
        " 'trend_ichimoku_base',\n",
        " 'trend_ichimoku_a',\n",
        " 'trend_ichimoku_b',\n",
        " 'trend_stc',\n",
        " 'trend_adx',\n",
        " 'trend_adx_pos',\n",
        " 'trend_adx_neg',\n",
        " 'trend_cci',\n",
        " 'trend_visual_ichimoku_a',\n",
        " 'trend_visual_ichimoku_b',\n",
        " 'trend_aroon_up',\n",
        " 'trend_aroon_down',\n",
        " 'trend_aroon_ind',\n",
        " 'trend_psar_up',\n",
        " 'trend_psar_down',\n",
        " 'trend_psar_up_indicator',\n",
        " 'trend_psar_down_indicator',\n",
        " 'momentum_rsi',\n",
        " 'momentum_stoch_rsi',\n",
        " 'momentum_stoch_rsi_k',\n",
        " 'momentum_stoch_rsi_d',\n",
        " 'momentum_tsi',\n",
        " 'momentum_uo',\n",
        " 'momentum_stoch',\n",
        " 'momentum_stoch_signal',\n",
        " 'momentum_wr',\n",
        " 'momentum_ao',\n",
        " 'momentum_roc',\n",
        " 'momentum_ppo',\n",
        " 'momentum_ppo_signal',\n",
        " 'momentum_ppo_hist',\n",
        " 'momentum_pvo',\n",
        " 'momentum_pvo_signal',\n",
        " 'momentum_pvo_hist',\n",
        " 'momentum_kama',\n",
        " 'others_dr',\n",
        " 'others_dlr',\n",
        " 'others_cr']"
      ],
      "metadata": {
        "id": "IZrP4drmKSlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train[predictors]\n",
        "y_train = train[\"Target\"]\n",
        "\n",
        "X_test = test[predictors]\n",
        "y_test = test[\"Target\"]"
      ],
      "metadata": {
        "id": "lj0wvT37KSiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "FrF1hz4lKSfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Supongamos que X_train y X_test son tus conjuntos de datos de características\n",
        "\n",
        "# Crea el objeto StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Ajusta el scaler en el conjunto de entrenamiento y transforma los datos\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# Aplica la misma transformación al conjunto de prueba\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "NhztFyIdKSaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# # Escalar los conjuntos de entrenamiento y prueba utilizando Min-Max Scaling\n",
        "# scaler = MinMaxScaler()\n",
        "# X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# # Resto del código para la creación y entrenamiento del modelo..."
      ],
      "metadata": {
        "id": "MZX5nO9HKSXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sequences_with_shifted_target(data, target, window_size):\n",
        "    sequences = []\n",
        "    labels = []\n",
        "\n",
        "    for i in range(len(data) - window_size):\n",
        "        sequence = data[i:i+window_size]\n",
        "        label = target[i+window_size]\n",
        "        sequences.append(sequence)\n",
        "        labels.append(label)\n",
        "\n",
        "    return np.array(sequences), np.array(labels)"
      ],
      "metadata": {
        "id": "r_bS1EWmKSU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "window_size = 50"
      ],
      "metadata": {
        "id": "nO2w4V6HKSSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_sequences, y_train_sequences = create_sequences_with_shifted_target(X_train_scaled, y_train, window_size)"
      ],
      "metadata": {
        "id": "brz3nZjvKSPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_sequences, y_test_sequences = create_sequences_with_shifted_target(X_test_scaled, y_test, window_size)\n"
      ],
      "metadata": {
        "id": "TCHUmmpQKSNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "XfMWyQwQKSKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crea el objeto Sequential y agrega capas\n",
        "\n",
        "drop_out = 0.2\n",
        "optimizador = Adam(learning_rate=1e-4)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, activation='relu', input_shape=(window_size, X_train_scaled.shape[1]), return_sequences=False))\n",
        "# model.add(Dropout(drop_out))\n",
        "# model.add(LSTM(256, activation='relu', return_sequences=True))\n",
        "# model.add(Dropout(drop_out))\n",
        "# model.add(LSTM(256, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# model = Sequential()\n",
        "# model.add(LSTM(256, activation='relu', input_shape=(X_train_scaled.shape[1], 1), return_sequences=True))\n",
        "# model.add(Dropout(drop_out))  # Capa de dropout para prevenir sobreajuste\n",
        "# model.add(LSTM(256, activation='relu', return_sequences=True))  # Segunda capa LSTM\n",
        "# # model.add(Dropout(drop_out))  # Capa de dropout adicional\n",
        "# # model.add(LSTM(64, activation='relu', return_sequences=True))\n",
        "# model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compila el modelo\n",
        "\n",
        "model.compile(optimizer=optimizador, loss='binary_crossentropy', metrics=['binary_accuracy'])\n"
      ],
      "metadata": {
        "id": "6nBSp_FBKSIG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_sequences, y_train_sequences, epochs=100, validation_split=0.2)"
      ],
      "metadata": {
        "id": "Pj1wNFtlKSFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R4rXBUR6KSDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FbSHfCsxKR9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PWmao3LmKR7H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}